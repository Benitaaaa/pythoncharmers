{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd111c56",
   "metadata": {},
   "source": [
    "# Organization Relationships Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install openai spacy requests pandas networkx pyvis fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d49c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model for named entity recognition (NER)\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load RoBERTa sentiment analysis model\n",
    "#sentiment_pipeline = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "\n",
    "# Configuration\n",
    "#CONFIG = {\n",
    "#    \"paths\": {\n",
    "#        \"pdf_dir\": \"./pdfs\",  # Directory containing PDFs\n",
    "#        \"output_json\": \"./processed/organizations-relationships.csv\",  # Output JSON file\n",
    "#    }\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312e3f9b-a2c6-4432-8fbb-8f61aef8599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organization_network.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import requests\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load spaCy model for Named Entity Recognition (NER)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Hugging Face sentiment analysis model\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# OpenAI API Key (Set this securely in your environment)\n",
    "client = openai.OpenAI(api_key=\"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\") \n",
    "\n",
    "# Function to summarize text using OpenAI GPT-4o-mini\n",
    "def summarize_text(text):\n",
    "    prompt = \"\"\"Identify the main points in the article provided.\n",
    "    Given these main points, find relationships involving entities of type Organization.\n",
    "    \\n\\nArticle:\\n\"\"\" + text[:4000]  # Truncate to avoid API limits\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            store=True,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        summary = completion.choices[0].message.content\n",
    "        return summary.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during summarization: {e}\")\n",
    "        return text  # Fallback to original text if API fails\n",
    "\n",
    "# Function to normalize organization names using DBpedia Spotlight\n",
    "def normalize_org_name(org_name):\n",
    "    url = \"https://api.dbpedia-spotlight.org/en/annotate\"\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "    params = {\"text\": org_name, \"confidence\": 0.5}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"Resources\" in data:\n",
    "                return data[\"Resources\"][0][\"@URI\"].split(\"/\")[-1]  # Extract DBpedia title\n",
    "    except Exception as e:\n",
    "        print(f\"Error normalizing {org_name}: {e}\")\n",
    "\n",
    "    return org_name  # Return original if not found\n",
    "\n",
    "# Function to analyze sentiment of a sentence\n",
    "def get_sentiment(sentence):\n",
    "    \"\"\"Analyze sentiment of a sentence using Transformers.\"\"\"\n",
    "    result = sentiment_pipeline(sentence)\n",
    "    sentiment_label = result[0]['label']  # 'POSITIVE' or 'NEGATIVE'\n",
    "    confidence = result[0]['score']\n",
    "\n",
    "    # If confidence is low, classify as NEUTRAL\n",
    "    if confidence < 0.7:\n",
    "        return 'NEUTRAL'\n",
    "    return sentiment_label\n",
    "\n",
    "# Function to extract text from PDFs\n",
    "def extract_text_from_pdfs(pdf_dir):\n",
    "    texts = []\n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            filepath = os.path.join(pdf_dir, filename)\n",
    "            with fitz.open(filepath) as doc:\n",
    "                text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "                \n",
    "                # Summarize the extracted text before further processing\n",
    "                summarized_text = summarize_text(text)\n",
    "                \n",
    "                texts.append((summarized_text, filename))  # Store summarized text with filename\n",
    "    return texts\n",
    "\n",
    "# Function to extract organization relationships with sentiment\n",
    "def extract_organization_relationships(text, filename):\n",
    "    \"\"\"Extract organization entities and relationships from text.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    relationships = []\n",
    "\n",
    "    # Create relationships between organizations in the same sentence\n",
    "    for sent in doc.sents:\n",
    "        sent_doc = nlp(sent.text)\n",
    "        entities_in_sent = [normalize_org_name(e.text) for e in sent_doc.ents if e.label_ == \"ORG\"]\n",
    "        entities_in_sent = [e for e in entities_in_sent if e]  # Remove None values\n",
    "\n",
    "        if len(entities_in_sent) >= 2:\n",
    "            sentiment = get_sentiment(sent.text)  # Get sentiment of the sentence\n",
    "            for i in range(len(entities_in_sent) - 1):\n",
    "                relationships.append({\n",
    "                    'source': entities_in_sent[i],\n",
    "                    'target': entities_in_sent[i + 1],\n",
    "                    'sentence': sent.text,\n",
    "                    'sentiment': sentiment,\n",
    "                    'source_file': filename\n",
    "                })\n",
    "\n",
    "    return relationships\n",
    "\n",
    "# Function to save relationships as CSV\n",
    "def save_relationships_to_csv(relationships, output_path):\n",
    "    df = pd.DataFrame(relationships, columns=[\"source\", \"target\", \"sentence\", \"sentiment\", \"source_file\"])\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "# Function to visualize organization relationships with sentiment-based colors\n",
    "def visualize_relationships(relationships):\n",
    "    \"\"\"Visualize organization relationships using Pyvis with sentiment-based edge colors.\"\"\"\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", notebook=True, cdn_resources='in_line')\n",
    "\n",
    "    # Add nodes (organizations)\n",
    "    organizations = set()\n",
    "    for relation in relationships:\n",
    "        organizations.add(relation['source'])\n",
    "        organizations.add(relation['target'])\n",
    "\n",
    "    for org in organizations:\n",
    "        net.add_node(org, label=org, color=\"blue\", size=15)\n",
    "\n",
    "    # Add edges with sentiment-based color\n",
    "    for relation in relationships:\n",
    "        sentiment = relation['sentiment']\n",
    "        if sentiment == \"POSITIVE\":\n",
    "            edge_color = \"green\"\n",
    "        elif sentiment == \"NEGATIVE\":\n",
    "            edge_color = \"red\"\n",
    "        else:\n",
    "            edge_color = \"gray\"\n",
    "\n",
    "        net.add_edge(relation['source'], relation['target'], width=2, color=edge_color, title=relation['sentence'])\n",
    "\n",
    "    # Save and show visualization\n",
    "    net.show(\"organization_network.html\")\n",
    "\n",
    "# Main script to process PDFs\n",
    "pdf_dir = \"/Users/benitaleonardi/Downloads/Datathon pdfs\"\n",
    "texts_with_sources = extract_text_from_pdfs(pdf_dir)\n",
    "\n",
    "all_relationships = []\n",
    "\n",
    "for text, filename in texts_with_sources:\n",
    "    relationships = extract_organization_relationships(text, filename)\n",
    "    all_relationships.extend(relationships)\n",
    "\n",
    "# Save relationships to CSV\n",
    "output_csv_path = \"output_relationships.csv\"\n",
    "save_relationships_to_csv(all_relationships, output_csv_path)\n",
    "\n",
    "# Visualize the relationships with sentiment-based edges\n",
    "visualize_relationships(all_relationships)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e29904-e7f6-4824-9c6b-7c126416e80a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
